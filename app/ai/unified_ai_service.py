"""
Unified AI Service - Combines Voice Processing and AI Assistant.
Provides free voice-to-text (local & API) and improved natural language understanding.
"""
import os
import re
import json
import logging
from typing import Optional

import httpx

logger = logging.getLogger(__name__)

# Try to import faster-whisper for local transcription
try:
    from faster_whisper import WhisperModel
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    logger.warning("faster-whisper not installed. Install for local offline transcription.")


class UnifiedAIService:
    """
    Unified AI Service that handles:
    - Voice transcription (local or API - FREE & paid options)
    - Text command understanding
    - Lead queries
    - Note categorization
    
    Transcription priority:
    1. Local faster-whisper (FREE, offline, fastest)
    2. HuggingFace API (FREE, online)
    3. OpenAI Whisper (paid, reliable)
    """
    
    # Class-level model cache
    _whisper_model = None
    _model_loaded = False
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.huggingface_token = os.getenv("HUGGINGFACE_TOKEN")
        self.local_whisper_model = os.getenv("LOCAL_WHISPER_MODEL", "base")  # tiny, base, small
        self.api_base_url = "http://localhost:8000"
    
    # ==================== VOICE PROCESSING ====================
    
    async def transcribe_voice(self, voice_content: bytes) -> str | None:
        """
        Transcribe voice to text.
        Priority: Local (faster-whisper) > HuggingFace API > OpenAI API
        """
        # 1. Try local faster-whisper (FREE, offline, fastest)
        if FASTER_WHISPER_AVAILABLE:
            result = await self._transcribe_local(voice_content)
            if result:
                logger.info("Used local faster-whisper transcription")
                return result
        
        # 2. Try HuggingFace API (FREE, online)
        if self.huggingface_token:
            result = await self._transcribe_huggingface(voice_content)
            if result:
                logger.info("Used HuggingFace API transcription")
                return result
        
        # 3. Try OpenAI Whisper (paid, reliable)
        if self.openai_api_key:
            result = await self._transcribe_openai(voice_content)
            if result:
                logger.info("Used OpenAI Whisper transcription")
                return result
        
        logger.error("No voice transcription service available")
        return None
    
    async def _transcribe_local(self, voice_content: bytes) -> str | None:
        """Transcribe using local faster-whisper (FREE, offline)."""
        try:
            # Load model once and cache it
            if not UnifiedAIService._whisper_model:
                logger.info(f"Loading local Whisper model: {self.local_whisper_model}")
                UnifiedAIService._whisper_model = WhisperModel(
                    self.local_whisper_model, 
                    device="cpu", 
                    compute_type="int8"
                )
                UnifiedAIService._model_loaded = True
            
            # Save to temp file (faster-whisper needs file path)
            import tempfile
            import asyncio
            
            # Run in executor to avoid blocking
            loop = asyncio.get_event_loop()
            
            def transcribe():
                with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as tmp:
                    tmp.write(voice_content)
                    tmp_path = tmp.name
                
                try:
                    segments, info = UnifiedAIService._whisper_model.transcribe(
                        tmp_path,
                        beam_size=5,
                        vad_filter=True,
                        vad_parameters=dict(min_silence_duration_ms=500)
                    )
                    
                    full_text = ""
                    for segment in segments:
                        full_text += segment.text.strip() + " "
                    
                    return full_text.strip()
                finally:
                    os.unlink(tmp_path)
            
            result = await loop.run_in_executor(None, transcribe)
            return result if result else None
            
        except Exception as e:
            logger.warning(f"Local transcription failed: {e}")
            return None
    
    async def _transcribe_huggingface(self, voice_content: bytes) -> str | None:
        """Transcribe using HuggingFace Inference API (FREE)."""
        try:
            async with httpx.AsyncClient() as client:
                files = {"file": ("voice.ogg", voice_content, "audio/ogg")}
                data = {"model": "openai/whisper-base"}
                headers = {"Authorization": f"Bearer {self.huggingface_token}"}
                
                response = await client.post(
                    "https://api-inference.huggingface.co/models/openai/whisper-base",
                    headers=headers,
                    files=files,
                    data=data,
                    timeout=30.0
                )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("text", "").strip()
            else:
                logger.warning(f"HuggingFace Whisper error: {response.status_code}")
                return None
                
        except Exception as e:
            logger.warning(f"HuggingFace transcription failed: {e}")
            return None
    
    async def _transcribe_openai(self, voice_content: bytes) -> str | None:
        """Transcribe using OpenAI Whisper API (paid)."""
        if not self.openai_api_key:
            return None
            
        try:
            files = {"file": ("voice.ogg", voice_content, "audio/ogg")}
            headers = {"Authorization": f"Bearer {self.openai_api_key}"}
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/audio/transcriptions",
                    headers=headers,
                    files=files,
                    data={"model": "whisper-1"},
                    timeout=30.0
                )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("text", "").strip()
            else:
                logger.error(f"OpenAI Whisper error: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"OpenAI transcription error: {e}")
            return None
    
    # ==================== COMMAND PARSING ====================
    
    def parse_command(self, text: str) -> dict:
        """Parse natural language text into structured command."""
        text_lower = text.lower()
        
        result = {
            "action": None,
            "query": None,
            "lead_data": {},
            "confidence": 0.5,
            "raw_text": text
        }
        
        # CREATE LEAD commands
        create_patterns = [
            "–¥–æ–¥–∞–π –ª—ñ–¥–∞", "–¥–æ–¥–∞–π –Ω–æ–≤–∏–π –ª—ñ–¥–∞", "–¥–æ–¥–∞–π –Ω–æ–≤–æ–≥–æ –ª—ñ–¥–∞",
            "—Å—Ç–≤–æ—Ä–∏ –ª—ñ–¥–∞", "–Ω–æ–≤–∏–π –ª—ñ–¥–∞", "—Å—Ç–≤–æ—Ä–∏ –Ω–æ–≤–æ–≥–æ –ª—ñ–¥–∞",
            "add lead", "create lead", "new lead", "add new lead"
        ]
        
        if any(p in text_lower for p in create_patterns):
            result["action"] = "create"
            result["lead_data"] = self._parse_lead_data(text)
            result["confidence"] = 0.9
            return result
        
        # SHOW LEADS / LIST commands
        list_patterns = [
            "–ø–æ–∫–∞–∂–∏ –ª—ñ–¥–∏", "–ø–æ–∫–∞–∂–∏ –≤—Å—ñ—Ö –ª—ñ–¥—ñ–≤", "—Å–ø–∏—Å–æ–∫ –ª—ñ–¥—ñ–≤",
            "show leads", "show all leads", "list leads", "–º–æ—ó –ª—ñ–¥–∏"
        ]
        
        if any(p in text_lower for p in list_patterns):
            result["action"] = "list"
            result["confidence"] = 0.9
            return result
        
        # NOTES commands
        show_notes_patterns = [
            "–ø–æ–∫–∞–∂–∏ –Ω–æ—Ç–∞—Ç–∫–∏", "–ø–æ–∫–∞–∂–∏ –∑–∞–º–µ—á–∞–Ω–∏—è", "show notes", 
            "–º–æ—ó –Ω–æ—Ç–∞—Ç–∫–∏", "–Ω–æ—Ç–∞—Ç–∫–∏ –ª—ñ–¥–∞"
        ]
        
        if any(p in text_lower for p in show_notes_patterns):
            result["action"] = "notes"
            result["confidence"] = 0.9
            return result
        
        # ADD NOTE commands
        note_patterns = [
            "–¥–æ–¥–∞–π –Ω–æ—Ç–∞—Ç–∫—É", "–¥–æ–¥–∞–π –∑–∞–º—ñ—Ç–∫—É", "–¥–æ–¥–∞–π note",
            "–∑–∞–ø–∏—à–∏ –Ω–æ—Ç–∞—Ç–∫—É", "create note", "add note"
        ]
        
        if any(p in text_lower for p in note_patterns):
            lead_id = self._extract_lead_id(text)
            result["action"] = "note"
            result["lead_data"] = {"lead_id": lead_id, "content": text}
            result["confidence"] = 0.8
            return result
        
        # STATS commands
        stats_patterns = [
            "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–∑–≤—ñ—Ç–∏", "stats", "show stats",
            "–¥–∞—à–±–æ—Ä–¥", "dashboard", "–ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"
        ]
        
        if any(p in text_lower for p in stats_patterns):
            result["action"] = "stats"
            result["confidence"] = 0.9
            return result
        
        # EDIT LEAD commands
        edit_patterns = [
            "—Ä–µ–¥–∞–≥—É–π –ª—ñ–¥–∞", "–∑–º—ñ–Ω–∏ –ª—ñ–¥–∞", "edit lead", "change lead",
            "–æ–Ω–æ–≤ –ª—ñ–¥–∞", "—Ä–µ–¥–∞–≥—É–π #", "–∑–º—ñ–Ω–∏ #"
        ]
        
        if any(p in text_lower for p in edit_patterns):
            lead_id = self._extract_lead_id(text)
            result["action"] = "edit"
            result["lead_data"] = {"lead_id": lead_id}
            result["confidence"] = 0.8
            return result
        
        # DELETE LEAD commands
        delete_patterns = [
            "–≤–∏–¥–∞–ª–∏ –ª—ñ–¥–∞", "–≤–∏–¥–∞–ª–∏—Ç–∏ –ª—ñ–¥–∞", "delete lead", "remove lead"
        ]
        
        if any(p in text_lower for p in delete_patterns):
            lead_id = self._extract_lead_id(text)
            result["action"] = "delete"
            result["lead_data"] = {"lead_id": lead_id}
            result["confidence"] = 0.8
            return result
        
        # SALES commands
        sales_patterns = [
            "–ø—Ä–æ–¥–∞–∂—ñ", "sales", "pipeline", "–≤–æ—Ä–æ–Ω–∫–∞",
            "–ø–æ–∫–∞–∂–∏ –ø—Ä–æ–¥–∞–∂—ñ", "show sales"
        ]
        
        if any(p in text_lower for p in sales_patterns):
            result["action"] = "sales"
            result["confidence"] = 0.9
            return result
        
        # Search queries
        search_patterns = ["–∑–Ω–∞–π–¥–∏", "–ø–æ—à—É–∫", "search", "find", "—à—É–∫–∞–π"]
        
        if any(p in text_lower for p in search_patterns):
            query = text
            for word in ["–∑–Ω–∞–π–¥–∏", "–ø–æ—à—É–∫", "search", "find", "—à—É–∫–∞–π"]:
                query = query.replace(word, "", 1).strip()
            if query and len(query) > 1:
                result["action"] = "search"
                result["query"] = query
                result["confidence"] = 0.7
                return result
        
        # Analysis queries
        analysis_patterns = [
            "—Ö—Ç–æ –Ω–∞–π–∫—Ä–∞—â", "—Ö—Ç–æ –Ω–∞–π–≥–∞—Ä—è—á", "best lead", "hot lead",
            "–∞–Ω–∞–ª—ñ–∑", "analyze", "–æ—Ü—ñ–Ω–∏", "score"
        ]
        
        if any(p in text_lower for p in analysis_patterns):
            result["action"] = "analyze"
            result["query"] = text
            result["confidence"] = 0.6
            return result
        
        # Unknown - use as AI query
        result["action"] = "ai_query"
        result["query"] = text
        result["confidence"] = 0.4
        
        return result
    
    def _extract_lead_id(self, text: str) -> int | None:
        """Extract lead ID from text."""
        patterns = [
            r'–ª—ñ–¥\s*#?(\d+)',
            r'lead\s*#?(\d+)',
            r'–¥–æ\s*–ª—ñ–¥[–∞—É]\s*#?(\d+)',
            r'–¥–ª—è\s*–ª—ñ–¥[–∞—É]\s*#?(\d+)',
            r'#(\d+)',
        ]
        for pattern in patterns:
            match = re.search(pattern, text.lower())
            if match:
                try:
                    return int(match.group(1))
                except:
                    pass
        return None
    
    def _parse_lead_data(self, text: str) -> dict:
        """Parse lead data from text/voice input."""
        text_lower = text.lower()
        
        result = {
            "name": None,
            "phone": None,
            "email": None,
            "source": "MANUAL",
            "domain": None
        }
        
        # Extract name
        name_patterns = [
            r'–ª—ñ–¥[–∞—É]?[.,]?\s*([–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+(?:\s+[–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+(?:\s+[–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+)?)?)',
            r'–¥–æ–¥–∞–π\s+(?:–Ω–æ–≤–æ–≥–æ\s+)?–ª—ñ–¥–∞[.,]?\s*([–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+(?:\s+[–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+(?:\s+[–ê-–Ø–∞-—è—ë–á—ó–Ü—ñ–Ñ—îA-Za-z]+)?)?)',
            r'([–ê-–Ø][–∞-—è—ë–á—ó–Ü—ñ–Ñ—î]+(?:\s+[–ê-–Ø][–∞-—è—ë–á—ó–Ü—ñ–Ñ—î]+)(?:\s+[–ê-–Ø][–∞-—è—ë–á—ó–Ü—ñ–Ñ—î]+)?)',
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                if len(name) > 2 and not any(kw in name.lower() for kw in ['–¥–æ–¥–∞–π', '–ª—ñ–¥–∞', '–Ω–æ–º–µ—Ä', '—Ç–µ–ª', 'email']):
                    result["name"] = name
                    break
        
        # Extract phone
        phone_patterns = [r'\+?380\d{9}', r'\+?\d{10,12}', r'\d{3}[-.\s]?\d{2}[-.\s]?\d{2}[-.\s]?\d{2}']
        for pattern in phone_patterns:
            match = re.search(pattern, text)
            if match:
                result["phone"] = match.group()
                break
        
        # Extract email
        email_match = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', text)
        if email_match:
            result["email"] = email_match.group()
        
        # Extract source
        if "—Å–∫–∞–Ω–µ—Ä" in text_lower or "scanner" in text_lower:
            result["source"] = "SCANNER"
        elif "–ø–∞—Ä—Ç–Ω–µ—Ä" in text_lower or "partner" in text_lower:
            result["source"] = "PARTNER"
        
        # Extract domain
        if "–ø–µ—Ä—à–∏–π" in text_lower or "first" in text_lower:
            result["domain"] = "FIRST"
        elif "–¥—Ä—É–≥–∏–π" in text_lower or "second" in text_lower:
            result["domain"] = "SECOND"
        elif "—Ç—Ä–µ—Ç—ñ–π" in text_lower or "third" in text_lower:
            result["domain"] = "THIRD"
        
        return result
    
    # ==================== AI QUERY PROCESSING ====================
    
    async def process_query(self, query: str, leads: list) -> str:
        """Process natural language query about leads using AI."""
        if not self.openai_api_key:
            return self._simple_query_response(query, leads)
        
        try:
            context = self._prepare_context(leads)
            system_prompt = self._build_prompt()
            user_prompt = f"Query: {query}\n\nLeads Data:\n{context}"
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.openai_api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "max_tokens": 500,
                        "temperature": 0.3
                    },
                    timeout=30.0
                )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                return self._simple_query_response(query, leads)
                
        except Exception as e:
            logger.error(f"AI query error: {e}")
            return self._simple_query_response(query, leads)
    
    def _simple_query_response(self, query: str, leads: list) -> str:
        """Simple rule-based response when AI is not available."""
        query_lower = query.lower()
        
        # Hot leads
        if "–≥–∞—Ä—è—á" in query_lower or "hot" in query_lower or "best" in query_lower:
            hot_leads = [l for l in leads if l.get("ai_score", 0) >= 0.6]
            if hot_leads:
                response = "üî• <b>–ì–∞—Ä—è—á—ñ –ª—ñ–¥–∏:</b>\n\n"
                for lead in hot_leads[:5]:
                    response += f"‚Ä¢ #{lead.get('id')}: {lead.get('full_name')} (score: {lead.get('ai_score', 0):.0%})\n"
                return response
            return "–ì–∞—Ä—è—á—ñ –ª—ñ–¥–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ."
        
        # Count by source
        if "—Å–∫–∞–Ω–µ—Ä" in query_lower or "scanner" in query_lower:
            count = len([l for l in leads if l.get("source") == "SCANNER"])
            return f"–õ—ñ–¥—ñ–≤ –∑—ñ —Å–∫–∞–Ω–µ—Ä–∞: <b>{count}</b>"
        
        if "–ø–∞—Ä—Ç–Ω–µ—Ä" in query_lower or "partner" in query_lower:
            count = len([l for l in leads if l.get("source") == "PARTNER"])
            return f"–õ—ñ–¥—ñ–≤ –≤—ñ–¥ –ø–∞—Ä—Ç–Ω–µ—Ä—ñ–≤: <b>{count}</b>"
        
        # Stage counts
        for stage in ["new", "contacted", "qualified", "transferred", "lost"]:
            if stage in query_lower:
                count = len([l for l in leads if l.get("stage", "").lower() == stage.upper()])
                return f"–õ—ñ–¥—ñ–≤ –≤ —Å—Ç–∞–¥—ñ—ó {stage}: <b>{count}</b>"
        
        # Default
        return f"–ó–Ω–∞–π–¥–µ–Ω–æ <b>{len(leads)}</b> –ª—ñ–¥—ñ–≤. –£—Ç–æ—á–Ω—ñ—Ç—å –≤–∞—à –∑–∞–ø–∏—Ç."
    
    def _prepare_context(self, leads: list) -> str:
        if not leads:
            return "No leads in database."
        
        sample = leads[:30]
        summaries = []
        for lead in sample:
            s = f"ID:{lead.get('id')} | {lead.get('full_name', 'N/A')} | {lead.get('source')} | {lead.get('stage')} | {lead.get('business_domain', '-')}"
            if lead.get('ai_score'):
                s += f" | Score:{lead.get('ai_score', 0):.0%}"
            summaries.append(s)
        return "\n".join(summaries)
    
    def _build_prompt(self) -> str:
        return """–¢–∏ ‚Äî CRM-–∞—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Å–∏—Å—Ç–µ–º–∏ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –ª—ñ–¥—Ä–∞–º–∏.

–î–æ—Å—Ç—É–ø–Ω—ñ –¥–∞–Ω—ñ: id, full_name, source (SCANNER/PARTNER/MANUAL), stage (NEW/CONTACTED/QUALIFIED/TRANSFERRED/LOST), business_domain (FIRST/SECOND/THIRD), ai_score (0.0-1.0).

–í–Ü–î–ü–û–í–Ü–î–ê–ô –£–ö–†–ê–á–ù–°–¨–ö–û–Æ!
–ë—É–¥—å –∫–æ—Ä–æ—Ç–∫–∏–º —ñ –∫–æ—Ä–∏—Å–Ω–∏–º.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è HTML (<b>, <i>, ‚Ä¢)."""
    
    # ==================== NOTE CATEGORIZATION ====================
    
    async def categorize_note(self, note_content: str) -> str:
        """Categorize a note."""
        if not self.openai_api_key:
            return self._simple_categorize(note_content)
        
        try:
            prompt = f"""–í–∏–∑–Ω–∞—á –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –Ω–æ—Ç–∞—Ç–∫–∏ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: contact, email, meeting, general, problem –∞–±–æ success.

–¢–µ–∫—Å—Ç: {note_content[:200]}"""
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {self.openai_api_key}"},
                    json={"model": "gpt-4o-mini", "messages": [{"role": "user", "content": prompt}], "max_tokens": 20},
                    timeout=10.0
                )
            
            if response.status_code == 200:
                cat = response.json()["choices"][0]["message"]["content"].strip().lower()
                valid = ["contact", "email", "meeting", "general", "problem", "success"]
                return cat if cat in valid else "general"
        except:
            pass
        
        return self._simple_categorize(note_content)
    
    def _simple_categorize(self, text: str) -> str:
        text_lower = text.lower()
        keywords = {
            "problem": ["–ø—Ä–æ–±–ª–µ–º", "–±—ñ–ª—å", "—Å–∫–∞—Ä–≥", "–ø–æ–≥–∞–Ω–æ", "issue"],
            "success": ["—É—Å–ø—ñ—Ö", "–≤—ñ–¥–º—ñ–Ω–Ω–æ", "–¥–æ–±—Ä–µ", "–≤–∏–≥—Ä–∞—à", "—É–≥–æ–¥"],
            "contact": ["–¥–∑–≤—ñ–Ω", "—Ç–µ–ª–µ—Ñ–æ–Ω", "—Ä–æ–∑–º–æ–≤", "call"],
            "email": ["email", "–ª–∏—Å—Ç", "–ø–æ—à—Ç–∞"],
            "meeting": ["–∑—É—Å—Ç—Ä—ñ—á", "–º—ñ—Ç–∏–Ω–≥", "–Ω–∞—Ä–∞–¥–∞"]
        }
        for cat, kws in keywords.items():
            if any(k in text_lower for k in kws):
                return cat
        return "general"


# Singleton
unified_ai = UnifiedAIService()
